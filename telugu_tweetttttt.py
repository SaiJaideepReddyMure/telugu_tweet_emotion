# -*- coding: utf-8 -*-
"""Telugu_tweetttttt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11A8v2U_3SUN-Jn-C9nSh1GpAODcjSyvW
"""

import nltk
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import re
import string
from sklearn.model_selection import train_test_split
import seaborn as sns
import os
from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import GRU



from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Bidirectional
from keras.preprocessing.text import Tokenizer

from google.colab import drive
drive.mount('/content/drive')

telugu_news_df = pd.read_csv('/content/drive/MyDrive/train_telugu_news.csv')

del telugu_news_df["heading"]
del telugu_news_df["SNo"]

del telugu_news_df["date"]

telugu_news_df.head()

telugu_news_df["body_processed"] = telugu_news_df["body"].str.replace('\u200c', '')
telugu_news_df["body_processed"] = telugu_news_df["body_processed"].str.replace('\n', '')
telugu_news_df["body_processed"] = telugu_news_df["body_processed"].str.replace('\t', '')
telugu_news_df["body_processed"] = telugu_news_df["body_processed"].str.replace('\xa0', '')

PUNCT = string.punctuation

def remove_punctuation(text):
    return text.translate(str.maketrans('', '', PUNCT))

topic_dic = {}

c = 0
for un in telugu_news_df["topic"].unique():
    if un not in topic_dic:
        topic_dic[un] = c
        c += 1

topic_dic

telugu_news_df["body_processed"] = telugu_news_df["body_processed"].apply(lambda text: remove_punctuation(text))

def func_topic(s):
    return topic_dic[s]

telugu_news_df["topic"] = telugu_news_df["topic"].apply(func_topic)
telugu_news_df["topic"]

texts =telugu_news_df["body_processed"].values
labels = telugu_news_df['topic'].values

tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(texts)
X = tokenizer.texts_to_sequences(texts)

X = pad_sequences(X, maxlen=150)

X_train, X_valid, y_train, y_valid = train_test_split(X, labels, test_size=0.2, random_state=42)

X_train,y_train=(X,labels)

import tensorflow as tf

model = tf.keras.models.Sequential([
        tf.keras.layers.Embedding(5000,16,input_length=150),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences = True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences = True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),
        tf.keras.layers.Dense(5,activation = 'softmax',)

])
model.compile(
    loss = 'sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

history=model.fit(X_train, y_train, validation_data=(X_valid,y_valid),epochs=5, batch_size=128)

history.history.keys()

from matplotlib import pyplot

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train'],loc='upper left')
plt.show()

import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train'],loc='upper left')
plt.show()

telugu_news_df = pd.read_csv('/content/drive/MyDrive/test_telugu_news.csv')

del telugu_news_df["heading"]
del telugu_news_df["SNo"]

del telugu_news_df["date"]

telugu_news_df.head()

telugu_news_df["body_processed"] = telugu_news_df["body"].str.replace('\u200c', '')
telugu_news_df["body_processed"] = telugu_news_df["body_processed"].str.replace('\n', '')
telugu_news_df["body_processed"] = telugu_news_df["body_processed"].str.replace('\t', '')
telugu_news_df["body_processed"] = telugu_news_df["body_processed"].str.replace('\xa0', '')

PUNCT = string.punctuation

def remove_punctuation(text):
    return text.translate(str.maketrans('', '', PUNCT))

topic_dic = {}

c = 0
for un in telugu_news_df["topic"].unique():
    if un not in topic_dic:
        topic_dic[un] = c
        c += 1

topic_dic

telugu_news_df["body_processed"] = telugu_news_df["body_processed"].apply(lambda text: remove_punctuation(text))

def func_topic(s):
    return topic_dic[s]

telugu_news_df["topic"] = telugu_news_df["topic"].apply(func_topic)
telugu_news_df["topic"]

texts =telugu_news_df["body_processed"].values
labels = telugu_news_df['topic'].values

texts[0]

tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(texts)
X = tokenizer.texts_to_sequences(texts)

X = pad_sequences(X, maxlen=150)

X_test,y_test=(X,labels)

y_test.shape

X_test.shape

y_pred=model.predict(X_test)

y_pred = np.array(y_pred)

# Find the index of the highest probability for each row
predicted_class_indices = np.argmax(y_pred, axis=1)

print("Predicted class indices shape:", predicted_class_indices.shape)

predicted_class_indices[4318]

y_test.shape

print("Average value:", np.mean(y_test))

df = pd.DataFrame({'Column1':y_test , 'Column2': predicted_class_indices})

print(df)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Assuming you have the true labels and predicted labels as numpy arrays
true_labels =  y_test
predicted_labels =predicted_class_indices
# Accuracy
accuracy = accuracy_score(true_labels, predicted_labels)
print(f"Accuracy: {accuracy:.2f}")

# Precision, Recall, F1-score (average='macro' calculates metrics independently for each class and then takes the unweighted mean)
precision = precision_score(true_labels, predicted_labels, average='macro')
recall = recall_score(true_labels, predicted_labels, average='macro')
f1 = f1_score(true_labels, predicted_labels, average='macro')
print(f"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-score: {f1:.2f}")

# Confusion Matrix
confusion_mat = confusion_matrix(true_labels, predicted_labels)
print("Confusion Matrix:")
print(confusion_mat)

from sklearn.metrics import classification_report
report = classification_report(y_test, predicted_labels, target_names=classnames)
print(report)

import tensorflow as tf

model = tf.keras.models.Sequential([
        tf.keras.layers.Embedding(5000,16,input_length=150),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences = True)),
        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),
        tf.keras.layers.Dense(6,activation = 'softmax',)

])
model.compile(
    loss = 'sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.fit(X_test, y_test, epochs=5, batch_size=20)

X_test[0]

y_test[5]



telugu_news_df = pd.read_parquet('/content/telugu_news_train.parquet',engine='pyarrow')

telugu_news_df.head()

telugu_news_df["title"][6214]

telugu_news_df["text"][6214]

telugu_news_df["t"][6214]